{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: Aly (Aleigha Sardina-Spevack)\n",
    "* Student pace: self paced\n",
    "* Scheduled project review date/time: 1/29/2019 @ 6:30pm EST\n",
    "* Instructor name: Eli \n",
    "* Blog post URL: https://medium.com/@sardina.aleigha/my-first-data-science-project-efce1e399893\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Prices in Kings County\n",
    "\n",
    "## Can we build a model to predict the housing prices in Kings County, Seattle?\n",
    "\n",
    "### Of course the answer to that question is 'Yes'!  It's why we're here.  So we'll go through, end to end, a data science model using the OSEMN framework to arrive at a formula to help predict the home prices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting off...\n",
    "\n",
    "Here are the column name definitions.  It's a good idea to keep these nearby as a reference.  It'll help us conceptualize what we are really working on.\n",
    "\n",
    "### Column Names and descriptions for Kings County Data Set\n",
    "* **id** - unique identified for a house\n",
    "* **dateDate** - house was sold\n",
    "* **pricePrice** -  is prediction target\n",
    "* **bedroomsNumber** -  of Bedrooms/House\n",
    "* **bathroomsNumber** -  of bathrooms/bedrooms\n",
    "* **sqft_livingsquare** -  footage of the home\n",
    "* **sqft_lotsquare** -  footage of the lot\n",
    "* **floorsTotal** -  floors (levels) in house\n",
    "* **waterfront** - House which has a view to a waterfront\n",
    "* **view** - Has been viewed\n",
    "* **condition** - How good the condition is ( Overall )\n",
    "* **grade** - overall grade given to the housing unit, based on King County grading system\n",
    "* **sqft_above** - square footage of house apart from basement\n",
    "* **sqft_basement** - square footage of the basement\n",
    "* **yr_built** - Built Year\n",
    "* **yr_renovated** - Year when house was renovated\n",
    "* **zipcode** - zip\n",
    "* **lat** - Latitude coordinate\n",
    "* **long** - Longitude coordinate\n",
    "* **sqft_living15** - The square footage of interior housing living space for the nearest 15 neighbors\n",
    "* **sqft_lot15** - The square footage of the land lots of the nearest 15 neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A bit about OSEMN\n",
    "\n",
    "OSEMN stands for Obtain, Scrub, Explore, Model, & iNterpret and this acronym provides us with the steps that we will take to create our Housing Price predictor.  It's a popular model and provides a good framework for working through a problem like this.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First things first...\n",
    "A few libraries as well as the data itself must be loaded into the notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library imports and using the magic key for inline plotting in matplot\n",
    "#this won't be everything that we need, but it's a good slection to start with\n",
    "#later on as we need more specific tools we can add them at that time.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is our 'Obtain' step\n",
    "\n",
    "In this case, we already have a .csv file ready to go.  Life isn't always this easy, but today it is so we can use pandas to import our full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  10/13/2014  221900.0         3       1.00         1180   \n",
       "1  6414100192   12/9/2014  538000.0         3       2.25         2570   \n",
       "2  5631500400   2/25/2015  180000.0         2       1.00          770   \n",
       "3  2487200875   12/9/2014  604000.0         4       3.00         1960   \n",
       "4  1954400510   2/18/2015  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650     1.0         NaN   0.0     ...          7        1180   \n",
       "1      7242     2.0         0.0   0.0     ...          7        2170   \n",
       "2     10000     1.0         0.0   0.0     ...          6         770   \n",
       "3      5000     1.0         0.0   0.0     ...          7        1050   \n",
       "4      8080     1.0         0.0   0.0     ...          8        1680   \n",
       "\n",
       "   sqft_basement yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0            0.0     1955           0.0    98178  47.5112 -122.257   \n",
       "1          400.0     1951        1991.0    98125  47.7210 -122.319   \n",
       "2            0.0     1933           NaN    98028  47.7379 -122.233   \n",
       "3          910.0     1965           0.0    98136  47.5208 -122.393   \n",
       "4            0.0     1987           0.0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading .csv dataset into a dataframe\n",
    "df = pd.read_csv('kc_house_data.csv')\n",
    "#viewing header to ensure it loaded properly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we start poking around a little to see what sort of data we have and getting a general of idea of the types of questions we need to ask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "0  10/13/2014  221900.0         3       1.00         1180      5650     1.0   \n",
       "1   12/9/2014  538000.0         3       2.25         2570      7242     2.0   \n",
       "2   2/25/2015  180000.0         2       1.00          770     10000     1.0   \n",
       "3   12/9/2014  604000.0         4       3.00         1960      5000     1.0   \n",
       "4   2/18/2015  510000.0         3       2.00         1680      8080     1.0   \n",
       "\n",
       "   waterfront  view  condition  grade  sqft_above  sqft_basement  yr_built  \\\n",
       "0         0.0   0.0          3      7        1180            0.0      1955   \n",
       "1         0.0   0.0          3      7        2170          400.0      1951   \n",
       "2         0.0   0.0          3      6         770            0.0      1933   \n",
       "3         0.0   0.0          5      7        1050          910.0      1965   \n",
       "4         0.0   0.0          3      8        1680            0.0      1987   \n",
       "\n",
       "   yr_renovated  zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "0           0.0    98178  47.5112 -122.257           1340        5650  \n",
       "1        1991.0    98125  47.7210 -122.319           1690        7639  \n",
       "2           0.0    98028  47.7379 -122.233           2720        8062  \n",
       "3           0.0    98136  47.5208 -122.393           1360        5000  \n",
       "4           0.0    98074  47.6168 -122.045           1800        7503  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we're not going to need the ID column so we can remove it right away\n",
    "df = df.drop('id',axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 20 columns):\n",
      "date             21597 non-null object\n",
      "price            21597 non-null float64\n",
      "bedrooms         21597 non-null int64\n",
      "bathrooms        21597 non-null float64\n",
      "sqft_living      21597 non-null int64\n",
      "sqft_lot         21597 non-null int64\n",
      "floors           21597 non-null float64\n",
      "waterfront       21597 non-null float64\n",
      "view             21597 non-null float64\n",
      "condition        21597 non-null int64\n",
      "grade            21597 non-null int64\n",
      "sqft_above       21597 non-null int64\n",
      "sqft_basement    21597 non-null float64\n",
      "yr_built         21597 non-null int64\n",
      "yr_renovated     21597 non-null float64\n",
      "zipcode          21597 non-null int64\n",
      "lat              21597 non-null float64\n",
      "long             21597 non-null float64\n",
      "sqft_living15    21597 non-null int64\n",
      "sqft_lot15       21597 non-null int64\n",
      "dtypes: float64(9), int64(10), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#getting a feel for the data by reviewing column names and looking at some info related to the values in each column/series\n",
    "#defining a column name veriable now so that we an use it later\n",
    "col_name = list(df.columns)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning or Scrubbing\n",
    "\n",
    "Hmmm... looks a bit messy.  We can see why we need to 'scrub' around in here \n",
    "\n",
    "\n",
    "After a little bit of exploring, it looks like we have some 'dirt' in our data that we'll need to clean up.  We can start with converting date to a datetime type.  This will make performing any furture operations on the date easier. Waterfront data seems to be missing some values, as does year renovated and view.  Then we have a text column for sqft_basement which doesn't match our other column with above grade sqft.  We'll walk through each of these one by one to see how we can tidy up a bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2014-10-13\n",
       "1       2014-12-09\n",
       "2       2015-02-25\n",
       "3       2014-12-09\n",
       "4       2015-02-18\n",
       "5       2014-05-12\n",
       "6       2014-06-27\n",
       "7       2015-01-15\n",
       "8       2015-04-15\n",
       "9       2015-03-12\n",
       "10      2015-04-03\n",
       "11      2014-05-27\n",
       "12      2014-05-28\n",
       "13      2014-10-07\n",
       "14      2015-03-12\n",
       "15      2015-01-24\n",
       "16      2014-07-31\n",
       "17      2014-05-29\n",
       "18      2014-12-05\n",
       "19      2015-04-24\n",
       "20      2014-05-14\n",
       "21      2014-08-26\n",
       "22      2014-07-03\n",
       "23      2014-05-16\n",
       "24      2014-11-20\n",
       "25      2014-11-03\n",
       "26      2014-06-26\n",
       "27      2014-12-01\n",
       "28      2014-06-24\n",
       "29      2015-03-02\n",
       "           ...    \n",
       "21567   2014-06-10\n",
       "21568   2014-12-02\n",
       "21569   2014-08-28\n",
       "21570   2014-10-15\n",
       "21571   2015-03-05\n",
       "21572   2014-11-13\n",
       "21573   2014-09-10\n",
       "21574   2014-05-14\n",
       "21575   2014-10-02\n",
       "21576   2015-04-16\n",
       "21577   2015-03-17\n",
       "21578   2014-10-17\n",
       "21579   2014-10-31\n",
       "21580   2014-08-13\n",
       "21581   2015-04-21\n",
       "21582   2014-10-13\n",
       "21583   2014-09-15\n",
       "21584   2014-10-15\n",
       "21585   2015-04-07\n",
       "21586   2014-06-26\n",
       "21587   2014-08-25\n",
       "21588   2015-01-26\n",
       "21589   2014-10-14\n",
       "21590   2015-03-26\n",
       "21591   2015-02-19\n",
       "21592   2014-05-21\n",
       "21593   2015-02-23\n",
       "21594   2014-06-23\n",
       "21595   2015-01-16\n",
       "21596   2014-10-15\n",
       "Name: date, Length: 21597, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21597.000000\n",
       "mean       285.716581\n",
       "std        439.819830\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%        550.000000\n",
       "max       4820.000000\n",
       "Name: sqft_basement, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reviewing our basement data\n",
    "df.sqft_basement.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,  400.,  910., 1530.,  730., 1700.,  300.,  970.,  760.,\n",
       "        720.,  700.,  820.,  780.,  790.,  330., 1620.,  360.,  588.,\n",
       "       1510.,  410.,  990.,  600.,  560.,  550., 1000., 1600.,  500.,\n",
       "       1040.,  880., 1010.,  240.,  265.,  290.,  800.,  540.,  710.,\n",
       "        840.,  380.,  770.,  480.,  570., 1490.,  620., 1250., 1270.,\n",
       "        120.,  650.,  180., 1130.,  450., 1640., 1460., 1020., 1030.,\n",
       "        750.,  640., 1070.,  490., 1310.,  630., 2000.,  390.,  430.,\n",
       "        850.,  210., 1430., 1950.,  440.,  220., 1160.,  860.,  580.,\n",
       "       2060., 1820., 1180.,  200., 1150., 1200.,  680.,  530., 1450.,\n",
       "       1170., 1080.,  960.,  280.,  870., 1100.,  460., 1400.,  660.,\n",
       "       1220.,  900.,  420., 1580., 1380.,  475.,  690.,  270.,  350.,\n",
       "        935., 1370.,  980., 1470.,  160.,  950.,   50.,  740., 1780.,\n",
       "       1900.,  340.,  470.,  370.,  140., 1760.,  130.,  520.,  890.,\n",
       "       1110.,  150., 1720.,  810.,  190., 1290.,  670., 1800., 1120.,\n",
       "       1810.,   60., 1050.,  940.,  310.,  930., 1390.,  610., 1830.,\n",
       "       1300.,  510., 1330., 1590.,  920., 1320., 1420., 1240., 1960.,\n",
       "       1560., 2020., 1190., 2110., 1280.,  250., 2390., 1230.,  170.,\n",
       "        830., 1260., 1410., 1340.,  590., 1500., 1140.,  260.,  100.,\n",
       "        320., 1480., 1060., 1284., 1670., 1350., 2570., 1090.,  110.,\n",
       "       2500.,   90., 1940., 1550., 2350., 2490., 1481., 1360., 1135.,\n",
       "       1520., 1850., 1660., 2130., 2600., 1690.,  243., 1210., 1024.,\n",
       "       1798., 1610., 1440., 1570., 1650.,  704., 1910., 1630., 2360.,\n",
       "       1852., 2090., 2400., 1790., 2150.,  230.,   70., 1680., 2100.,\n",
       "       3000., 1870., 1710., 2030.,  875., 1540., 2850., 2170.,  506.,\n",
       "        906.,  145., 2040.,  784., 1750.,  374.,  518., 2720., 2730.,\n",
       "       1840., 3480., 2160., 1920., 2330., 1860., 2050., 4820., 1913.,\n",
       "         80., 2010., 3260., 2200.,  415., 1730.,  652., 2196., 1930.,\n",
       "        515.,   40., 2080., 2580., 1548., 1740.,  235.,  861., 1890.,\n",
       "       2220.,  792., 2070., 4130., 2250., 2240., 1990.,  768., 2550.,\n",
       "        435., 1008., 2300., 2610.,  666., 3500.,  172., 1816., 2190.,\n",
       "       1245., 1525., 1880.,  862.,  946., 1281.,  414., 2180.,  276.,\n",
       "       1248.,  602.,  516.,  176.,  225., 1275.,  266.,  283.,   65.,\n",
       "       2310.,   10., 1770., 2120.,  295.,  207.,  915.,  556.,  417.,\n",
       "        143.,  508., 2810.,   20.,  274.,  248.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking to see how many unique values there are.  \n",
    "#this could tell us if there is something about the data that may need to be fixed\n",
    "df.sqft_basement.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah ha!  It looks like we've encountered a common problem.  A whole data series is represented as a string ebcause of one value.  In our case a '?'.  We should see how many '?'s there are before we move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       13280\n",
       "600.0       217\n",
       "500.0       209\n",
       "700.0       208\n",
       "800.0       201\n",
       "400.0       184\n",
       "1000.0      148\n",
       "900.0       142\n",
       "300.0       142\n",
       "200.0       105\n",
       "750.0       104\n",
       "450.0       103\n",
       "530.0       103\n",
       "480.0       103\n",
       "720.0        98\n",
       "620.0        90\n",
       "580.0        84\n",
       "840.0        83\n",
       "420.0        81\n",
       "860.0        79\n",
       "670.0        78\n",
       "1100.0       78\n",
       "780.0        76\n",
       "550.0        76\n",
       "650.0        75\n",
       "240.0        74\n",
       "680.0        73\n",
       "380.0        73\n",
       "850.0        72\n",
       "360.0        72\n",
       "          ...  \n",
       "2600.0        1\n",
       "2610.0        1\n",
       "276.0         1\n",
       "274.0         1\n",
       "1245.0        1\n",
       "143.0         1\n",
       "266.0         1\n",
       "862.0         1\n",
       "2180.0        1\n",
       "415.0         1\n",
       "243.0         1\n",
       "1135.0        1\n",
       "1525.0        1\n",
       "3000.0        1\n",
       "172.0         1\n",
       "225.0         1\n",
       "518.0         1\n",
       "935.0         1\n",
       "1920.0        1\n",
       "1930.0        1\n",
       "1990.0        1\n",
       "588.0         1\n",
       "1548.0        1\n",
       "2390.0        1\n",
       "602.0         1\n",
       "915.0         1\n",
       "295.0         1\n",
       "1281.0        1\n",
       "2130.0        1\n",
       "906.0         1\n",
       "Name: sqft_basement, Length: 303, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sqft_basement'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 452 ? and 12798 0s.  Seems like basements aren't popular in Kings County.  Let's change our ? to 0's since 0 is the mode of the dataset by a very large margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing ? to 0.0 so our data set reads as a floating point number, eventually.\n",
    "df['sqft_basement'] = df['sqft_basement'].replace('?', '0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21597.000000\n",
       "mean       285.716581\n",
       "std        439.819830\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%        550.000000\n",
       "max       4820.000000\n",
       "Name: sqft_basement, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at our data series again \n",
    "df.sqft_basement.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,  400.,  910., 1530.,  730., 1700.,  300.,  970.,  760.,\n",
       "        720.,  700.,  820.,  780.,  790.,  330., 1620.,  360.,  588.,\n",
       "       1510.,  410.,  990.,  600.,  560.,  550., 1000., 1600.,  500.,\n",
       "       1040.,  880., 1010.,  240.,  265.,  290.,  800.,  540.,  710.,\n",
       "        840.,  380.,  770.,  480.,  570., 1490.,  620., 1250., 1270.,\n",
       "        120.,  650.,  180., 1130.,  450., 1640., 1460., 1020., 1030.,\n",
       "        750.,  640., 1070.,  490., 1310.,  630., 2000.,  390.,  430.,\n",
       "        850.,  210., 1430., 1950.,  440.,  220., 1160.,  860.,  580.,\n",
       "       2060., 1820., 1180.,  200., 1150., 1200.,  680.,  530., 1450.,\n",
       "       1170., 1080.,  960.,  280.,  870., 1100.,  460., 1400.,  660.,\n",
       "       1220.,  900.,  420., 1580., 1380.,  475.,  690.,  270.,  350.,\n",
       "        935., 1370.,  980., 1470.,  160.,  950.,   50.,  740., 1780.,\n",
       "       1900.,  340.,  470.,  370.,  140., 1760.,  130.,  520.,  890.,\n",
       "       1110.,  150., 1720.,  810.,  190., 1290.,  670., 1800., 1120.,\n",
       "       1810.,   60., 1050.,  940.,  310.,  930., 1390.,  610., 1830.,\n",
       "       1300.,  510., 1330., 1590.,  920., 1320., 1420., 1240., 1960.,\n",
       "       1560., 2020., 1190., 2110., 1280.,  250., 2390., 1230.,  170.,\n",
       "        830., 1260., 1410., 1340.,  590., 1500., 1140.,  260.,  100.,\n",
       "        320., 1480., 1060., 1284., 1670., 1350., 2570., 1090.,  110.,\n",
       "       2500.,   90., 1940., 1550., 2350., 2490., 1481., 1360., 1135.,\n",
       "       1520., 1850., 1660., 2130., 2600., 1690.,  243., 1210., 1024.,\n",
       "       1798., 1610., 1440., 1570., 1650.,  704., 1910., 1630., 2360.,\n",
       "       1852., 2090., 2400., 1790., 2150.,  230.,   70., 1680., 2100.,\n",
       "       3000., 1870., 1710., 2030.,  875., 1540., 2850., 2170.,  506.,\n",
       "        906.,  145., 2040.,  784., 1750.,  374.,  518., 2720., 2730.,\n",
       "       1840., 3480., 2160., 1920., 2330., 1860., 2050., 4820., 1913.,\n",
       "         80., 2010., 3260., 2200.,  415., 1730.,  652., 2196., 1930.,\n",
       "        515.,   40., 2080., 2580., 1548., 1740.,  235.,  861., 1890.,\n",
       "       2220.,  792., 2070., 4130., 2250., 2240., 1990.,  768., 2550.,\n",
       "        435., 1008., 2300., 2610.,  666., 3500.,  172., 1816., 2190.,\n",
       "       1245., 1525., 1880.,  862.,  946., 1281.,  414., 2180.,  276.,\n",
       "       1248.,  602.,  516.,  176.,  225., 1275.,  266.,  283.,   65.,\n",
       "       2310.,   10., 1770., 2120.,  295.,  207.,  915.,  556.,  417.,\n",
       "        143.,  508., 2810.,   20.,  274.,  248.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sqft_basement.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casting our column as a string\n",
    "df['sqft_basement'] = df['sqft_basement'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21597.000000\n",
       "mean       285.716581\n",
       "std        439.819830\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%        550.000000\n",
       "max       4820.000000\n",
       "Name: sqft_basement, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sqft_basement.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good.  We'll have a bit more to do before we can wrap our heads around what our data looks like.  This is, however, an iterative process and we should expect more tidying do to after this first round.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0., 1991., 2002., 2010., 1992., 2013., 1994., 1978., 2005.,\n",
       "       2003., 1984., 1954., 2014., 2011., 1983., 1945., 1990., 1988.,\n",
       "       1977., 1981., 1995., 2000., 1999., 1998., 1970., 1989., 2004.,\n",
       "       1986., 2007., 1987., 2006., 1985., 2001., 1980., 1971., 1979.,\n",
       "       1997., 1950., 1969., 1948., 2009., 2015., 1974., 2008., 1968.,\n",
       "       2012., 1963., 1951., 1962., 1953., 1993., 1996., 1955., 1982.,\n",
       "       1956., 1940., 1976., 1946., 1975., 1964., 1973., 1957., 1959.,\n",
       "       1960., 1967., 1965., 1934., 1972., 1944., 1958.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.yr_renovated.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take care of that nan and make it a 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll change all the nan to 0\n",
    "df['yr_renovated'] = df.yr_renovated.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0., 1991., 2002., 2010., 1992., 2013., 1994., 1978., 2005.,\n",
       "       2003., 1984., 1954., 2014., 2011., 1983., 1945., 1990., 1988.,\n",
       "       1977., 1981., 1995., 2000., 1999., 1998., 1970., 1989., 2004.,\n",
       "       1986., 2007., 1987., 2006., 1985., 2001., 1980., 1971., 1979.,\n",
       "       1997., 1950., 1969., 1948., 2009., 2015., 1974., 2008., 1968.,\n",
       "       2012., 1963., 1951., 1962., 1953., 1993., 1996., 1955., 1982.,\n",
       "       1956., 1940., 1976., 1946., 1975., 1964., 1973., 1957., 1959.,\n",
       "       1960., 1967., 1965., 1934., 1972., 1944., 1958.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.yr_renovated.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the 0 value to 'NaN'\n",
    "df['yr_renovated'] = df.yr_renovated.replace('NaN', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0., 1991., 2002., 2010., 1992., 2013., 1994., 1978., 2005.,\n",
       "       2003., 1984., 1954., 2014., 2011., 1983., 1945., 1990., 1988.,\n",
       "       1977., 1981., 1995., 2000., 1999., 1998., 1970., 1989., 2004.,\n",
       "       1986., 2007., 1987., 2006., 1985., 2001., 1980., 1971., 1979.,\n",
       "       1997., 1950., 1969., 1948., 2009., 2015., 1974., 2008., 1968.,\n",
       "       2012., 1963., 1951., 1962., 1953., 1993., 1996., 1955., 1982.,\n",
       "       1956., 1940., 1976., 1946., 1975., 1964., 1973., 1957., 1959.,\n",
       "       1960., 1967., 1965., 1934., 1972., 1944., 1958.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.yr_renovated.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 20 columns):\n",
      "date             21597 non-null object\n",
      "price            21597 non-null float64\n",
      "bedrooms         21597 non-null int64\n",
      "bathrooms        21597 non-null float64\n",
      "sqft_living      21597 non-null int64\n",
      "sqft_lot         21597 non-null int64\n",
      "floors           21597 non-null float64\n",
      "waterfront       21597 non-null float64\n",
      "view             21597 non-null float64\n",
      "condition        21597 non-null int64\n",
      "grade            21597 non-null int64\n",
      "sqft_above       21597 non-null int64\n",
      "sqft_basement    21597 non-null float64\n",
      "yr_built         21597 non-null int64\n",
      "yr_renovated     21597 non-null float64\n",
      "zipcode          21597 non-null int64\n",
      "lat              21597 non-null float64\n",
      "long             21597 non-null float64\n",
      "sqft_living15    21597 non-null int64\n",
      "sqft_lot15       21597 non-null int64\n",
      "dtypes: float64(9), int64(10), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#checking the dataframe again to see what it looks like now\n",
    "#this is a good habit to get into, jsut to make sure evrything is doign what we expect it to\n",
    "#Spoiler!  You'll see an example of why father down\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better!  Onto the waterfront series, let's see what that looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21597.000000\n",
       "mean         0.006760\n",
       "std          0.081944\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: waterfront, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.waterfront.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.waterfront.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not what I expected!  It looks like a categorical data set.  Either the property is on the waterfront or it's not, or the data is not available.  The problem here is that it is stored as a floating point number.  This can lead to some improper inferences regarding our data. Luckily this isn't too complicated to fix.  Shall we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making our nan into 0's consistent\n",
    "df['waterfront'] = df.waterfront.fillna('0.0')\n",
    "#Casting our column as a string\n",
    "df['waterfront'] = df['waterfront'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21597.000000\n",
       "mean         0.006760\n",
       "std          0.081944\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: waterfront, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking again to make sure this worked\n",
    "df.waterfront.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.waterfront.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 20 columns):\n",
      "date             21597 non-null object\n",
      "price            21597 non-null float64\n",
      "bedrooms         21597 non-null int64\n",
      "bathrooms        21597 non-null float64\n",
      "sqft_living      21597 non-null int64\n",
      "sqft_lot         21597 non-null int64\n",
      "floors           21597 non-null float64\n",
      "waterfront       21597 non-null float64\n",
      "view             21597 non-null float64\n",
      "condition        21597 non-null int64\n",
      "grade            21597 non-null int64\n",
      "sqft_above       21597 non-null int64\n",
      "sqft_basement    21597 non-null float64\n",
      "yr_built         21597 non-null int64\n",
      "yr_renovated     21597 non-null float64\n",
      "zipcode          21597 non-null int64\n",
      "lat              21597 non-null float64\n",
      "long             21597 non-null float64\n",
      "sqft_living15    21597 non-null int64\n",
      "sqft_lot15       21597 non-null int64\n",
      "dtypes: float64(9), int64(10), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better and better everytime.  We'll do a little bit more with that data series later, but for now we just have one more column to clean before we do some more exploring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21597.000000\n",
       "mean         0.233181\n",
       "std          0.764673\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          4.000000\n",
       "Name: view, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.view.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 3., 4., 2., 1.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.view.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh look, another category.  Looks like we're missing some data as well.  First, let's handle this the same way as the waterfront tag.  Then we'll see about the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making our nan into 0's consistent\n",
    "df['view'] = df.view.fillna('0.0')\n",
    "#Casting our column as a string\n",
    "df['view'] = df['view'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 3., 4., 2., 1.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.view.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21597.000000\n",
       "mean         0.233181\n",
       "std          0.764673\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          4.000000\n",
       "Name: view, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.view.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 20 columns):\n",
      "date             21597 non-null object\n",
      "price            21597 non-null float64\n",
      "bedrooms         21597 non-null int64\n",
      "bathrooms        21597 non-null float64\n",
      "sqft_living      21597 non-null int64\n",
      "sqft_lot         21597 non-null int64\n",
      "floors           21597 non-null float64\n",
      "waterfront       21597 non-null float64\n",
      "view             21597 non-null float64\n",
      "condition        21597 non-null int64\n",
      "grade            21597 non-null int64\n",
      "sqft_above       21597 non-null int64\n",
      "sqft_basement    21597 non-null float64\n",
      "yr_built         21597 non-null int64\n",
      "yr_renovated     21597 non-null float64\n",
      "zipcode          21597 non-null int64\n",
      "lat              21597 non-null float64\n",
      "long             21597 non-null float64\n",
      "sqft_living15    21597 non-null int64\n",
      "sqft_lot15       21597 non-null int64\n",
      "dtypes: float64(9), int64(10), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's have a look-see!\n",
    "\n",
    "Our initial cleaning is done so let's have a look at the data.  In my opinion this is the exciting part: where we learn enough about the data to start asking some fun questions.\n",
    "\n",
    "## Time to go Explore!\n",
    "\n",
    "I don't know about you, but exploring the Seattle Metro sounds like fun to me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date \n",
      " count         21597\n",
      "unique          372\n",
      "top       6/23/2014\n",
      "freq            142\n",
      "Name: date, dtype: object \n",
      "\n",
      "price \n",
      " count    2.159700e+04\n",
      "mean     5.402966e+05\n",
      "std      3.673681e+05\n",
      "min      7.800000e+04\n",
      "25%      3.220000e+05\n",
      "50%      4.500000e+05\n",
      "75%      6.450000e+05\n",
      "max      7.700000e+06\n",
      "Name: price, dtype: float64 \n",
      "\n",
      "bedrooms \n",
      " count    21597.000000\n",
      "mean         3.373200\n",
      "std          0.926299\n",
      "min          1.000000\n",
      "25%          3.000000\n",
      "50%          3.000000\n",
      "75%          4.000000\n",
      "max         33.000000\n",
      "Name: bedrooms, dtype: float64 \n",
      "\n",
      "bathrooms \n",
      " count    21597.000000\n",
      "mean         2.115826\n",
      "std          0.768984\n",
      "min          0.500000\n",
      "25%          1.750000\n",
      "50%          2.250000\n",
      "75%          2.500000\n",
      "max          8.000000\n",
      "Name: bathrooms, dtype: float64 \n",
      "\n",
      "sqft_living \n",
      " count    21597.000000\n",
      "mean      2080.321850\n",
      "std        918.106125\n",
      "min        370.000000\n",
      "25%       1430.000000\n",
      "50%       1910.000000\n",
      "75%       2550.000000\n",
      "max      13540.000000\n",
      "Name: sqft_living, dtype: float64 \n",
      "\n",
      "sqft_lot \n",
      " count    2.159700e+04\n",
      "mean     1.509941e+04\n",
      "std      4.141264e+04\n",
      "min      5.200000e+02\n",
      "25%      5.040000e+03\n",
      "50%      7.618000e+03\n",
      "75%      1.068500e+04\n",
      "max      1.651359e+06\n",
      "Name: sqft_lot, dtype: float64 \n",
      "\n",
      "floors \n",
      " count    21597.000000\n",
      "mean         1.494096\n",
      "std          0.539683\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          1.500000\n",
      "75%          2.000000\n",
      "max          3.500000\n",
      "Name: floors, dtype: float64 \n",
      "\n",
      "waterfront \n",
      " count    21597.000000\n",
      "mean         0.006760\n",
      "std          0.081944\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: waterfront, dtype: float64 \n",
      "\n",
      "view \n",
      " count    21597.000000\n",
      "mean         0.233181\n",
      "std          0.764673\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          4.000000\n",
      "Name: view, dtype: float64 \n",
      "\n",
      "condition \n",
      " count    21597.000000\n",
      "mean         3.409825\n",
      "std          0.650546\n",
      "min          1.000000\n",
      "25%          3.000000\n",
      "50%          3.000000\n",
      "75%          4.000000\n",
      "max          5.000000\n",
      "Name: condition, dtype: float64 \n",
      "\n",
      "grade \n",
      " count    21597.000000\n",
      "mean         7.657915\n",
      "std          1.173200\n",
      "min          3.000000\n",
      "25%          7.000000\n",
      "50%          7.000000\n",
      "75%          8.000000\n",
      "max         13.000000\n",
      "Name: grade, dtype: float64 \n",
      "\n",
      "sqft_above \n",
      " count    21597.000000\n",
      "mean      1788.596842\n",
      "std        827.759761\n",
      "min        370.000000\n",
      "25%       1190.000000\n",
      "50%       1560.000000\n",
      "75%       2210.000000\n",
      "max       9410.000000\n",
      "Name: sqft_above, dtype: float64 \n",
      "\n",
      "sqft_basement \n",
      " count    21597.000000\n",
      "mean       285.716581\n",
      "std        439.819830\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%        550.000000\n",
      "max       4820.000000\n",
      "Name: sqft_basement, dtype: float64 \n",
      "\n",
      "yr_built \n",
      " count    21597.000000\n",
      "mean      1970.999676\n",
      "std         29.375234\n",
      "min       1900.000000\n",
      "25%       1951.000000\n",
      "50%       1975.000000\n",
      "75%       1997.000000\n",
      "max       2015.000000\n",
      "Name: yr_built, dtype: float64 \n",
      "\n",
      "yr_renovated \n",
      " count    21597.000000\n",
      "mean        68.758207\n",
      "std        364.037499\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max       2015.000000\n",
      "Name: yr_renovated, dtype: float64 \n",
      "\n",
      "zipcode \n",
      " count    21597.000000\n",
      "mean     98077.951845\n",
      "std         53.513072\n",
      "min      98001.000000\n",
      "25%      98033.000000\n",
      "50%      98065.000000\n",
      "75%      98118.000000\n",
      "max      98199.000000\n",
      "Name: zipcode, dtype: float64 \n",
      "\n",
      "lat \n",
      " count    21597.000000\n",
      "mean        47.560093\n",
      "std          0.138552\n",
      "min         47.155900\n",
      "25%         47.471100\n",
      "50%         47.571800\n",
      "75%         47.678000\n",
      "max         47.777600\n",
      "Name: lat, dtype: float64 \n",
      "\n",
      "long \n",
      " count    21597.000000\n",
      "mean      -122.213982\n",
      "std          0.140724\n",
      "min       -122.519000\n",
      "25%       -122.328000\n",
      "50%       -122.231000\n",
      "75%       -122.125000\n",
      "max       -121.315000\n",
      "Name: long, dtype: float64 \n",
      "\n",
      "sqft_living15 \n",
      " count    21597.000000\n",
      "mean      1986.620318\n",
      "std        685.230472\n",
      "min        399.000000\n",
      "25%       1490.000000\n",
      "50%       1840.000000\n",
      "75%       2360.000000\n",
      "max       6210.000000\n",
      "Name: sqft_living15, dtype: float64 \n",
      "\n",
      "sqft_lot15 \n",
      " count     21597.000000\n",
      "mean      12758.283512\n",
      "std       27274.441950\n",
      "min         651.000000\n",
      "25%        5100.000000\n",
      "50%        7620.000000\n",
      "75%       10083.000000\n",
      "max      871200.000000\n",
      "Name: sqft_lot15, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col,'\\n',df[col].describe(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table tells us plenty of great information about housing in King County.  For example...\n",
    "\n",
    "* The Mean price of a house sold is 540,296USD\n",
    "* The Highest price of a house sold is 7,700,000USD\n",
    "* The average number of bedrooms per home is 3, number of bathrooms is 2, with the largest home having 33 bedrooms!\n",
    "* The average livable square feet is 2,080sqft, with the smallest home having only 370 sqft and the largest with over 13,500!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    19485\n",
       "2.0      957\n",
       "3.0      508\n",
       "1.0      330\n",
       "4.0      317\n",
       "Name: view, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['view'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that 19,485 of the listed homes have not logged a viewing, where 317 have already been viewed 4 times.\n",
    "\n",
    "We will start using some visualations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df.bedrooms, order = df['bedrooms'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the col_name variable to build a for lopp to plot some histograms of our data to get a feel for the distributions\n",
    "#first we'll need to update col_name to get rid of the columns that contain only strings: it'll make our for loop throw an error\n",
    "#we're leaving out yr_renovated since this only applies to a portion of our data.\n",
    "col_name =['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', \n",
    "           'condition', 'grade', 'sqft_above','sqft_basement','yr_built', 'zipcode', \n",
    "           'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
    "\n",
    "for col in col_name:\n",
    "    df[col].plot.hist( figsize= (6,6))\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes!  Most of these look like they have significant skew.  First we're going to take out floors and condition because they definitely aren't continuous variables.  Then we can try to noramlize these and add a kde plot to see if we can clean these up a bit and get a better picture.   I think we might have some additional non-continuous variables, but it'll be a clearer picture in a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once again we'll use a for loop to iterate through each of the columns \n",
    "continuous = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',  'grade',\n",
    "              'sqft_above','sqft_basement','yr_built', 'zipcode', 'lat', 'long', \n",
    "              'sqft_living15', 'sqft_lot15']\n",
    "\n",
    "for col in continuous:\n",
    "    df[col].plot.hist(normed=True)\n",
    "    df[col].plot.kde(label=col)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My hunch was proved correct.  Look at the orange line for grade, bedroom and bathroom.  Clearly these are not continuous.  We should handle these categories by so our eventual regression will function properly.  \n",
    "\n",
    "Before we get to all that we should check for multicollinearity to ensure our analysis will be readable and clear.  It may actually save us some code, by telling us that we can remove some variables that we would have needed to cleaned or managed in another way.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at a correlation matrix\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a big matrix, let's simplify this a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df.corr()) > 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a little better.  It looks like number of bathrooms, grade, and square feet above grade are  highly correlated with squarefeet of living space.  I think we can make this even clearer though.\n",
    "\n",
    "Let's look at a heat map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), center=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I see another pairs with high collinearity; square feet of living space of the nearest 15 neighbors.  I think the best thing to do would be to create a copy of our data frame and drop some of the columns that are highly correlated.\n",
    "\n",
    "This revealed another surprise: latitude and longitude aren't correlated with zipcode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe copy\n",
    "df_pred = df\n",
    "\n",
    "#and as always checking out dataframe\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping some correlated columns we're going to leave in square feet of the living space then get rid everything else.\n",
    "#we are also going to drop some columns that essentially do the same thing \n",
    "for col in ['bathrooms','sqft_above','grade','sqft_living15']:\n",
    "    df_pred.drop([col], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking our loop\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is even cleaner time to handle categorical varibles.  Let's look at the cleaned up version of the dataframe and review our KDE plots and histograms again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous2 = ['price', 'bedrooms', 'sqft_living', 'sqft_lot','sqft_basement','yr_built', 'zipcode', 'lat', 'long', 'sqft_lot15']\n",
    "\n",
    "for col in continuous2:\n",
    "    df[col].plot.hist(normed=True)\n",
    "    df[col].plot.kde(label=col)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have categorical variables, we'll one-hot encode them.  The first one we'll look at is bedrooms.  Before we do that though, we'll import the encoder from scikit-learn to make our jobs easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing an additional tool from a popular stats library SciKitLearn\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we'll convert bedrooms to a category then we can tranform it into a one-hot encoded dataframe\n",
    "beds = df.bedrooms.astype('category')\n",
    "beds_dummies = lb.fit_transform(beds)\n",
    "# converting to a dataframe\n",
    "beds_dum_df = pd.DataFrame(beds_dummies, columns=lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking our dataframe to ensure it worked\n",
    "beds_dum_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33 bedrooms!  I wonder how many properties have 33 bedrooms.  That seems way like it might through our data off.  We can sum the column and if it's a low enough number we can remove it once we replace the columns in our actual dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we remove the original column and add back the dummy encoded columns\n",
    "bed_dum = pd.get_dummies(df['bedrooms'],prefix='bed')\n",
    "df_pred = df_pred.drop(['bedrooms'], axis=1)\n",
    "df_pred= pd.concat([df_pred,bed_dum], axis=1)\n",
    "#checking our dataframe\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['bed_33'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one.  Somehow, either a mega mansion or a multifamily property snuck into out data.  Out it goes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the row that contains a one in our 'bed_33' column\n",
    "df_pred.drop(df_pred[df_pred.bed_33 == 1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we'll check out the column sum to ensure it's gone, then delete the whole column\n",
    "df_pred['bed_33'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.drop(['bed_33'], axis=1, inplace=True)\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll want to convert condition to a categorical variable as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convering the next series to a category then we can tranform it into a one-hot encoded dataframe\n",
    "condition = df.condition.astype('category')\n",
    "condition_dummies = lb.fit_transform(condition)\n",
    "#converting to a dataframe\n",
    "condition_dum_df = pd.DataFrame(condition_dummies, columns=lb.classes_)\n",
    "#Here we remove the original column and add back the dummy encoded columns\n",
    "cond_dum = pd.get_dummies(df['condition'],prefix='condition')\n",
    "df_pred = df_pred.drop(['condition'], axis=1)\n",
    "df_pred= pd.concat([df_pred,cond_dum], axis=1)\n",
    "#checking our dataframe\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned our data, we can get to the fun stuff...\n",
    "\n",
    "\n",
    "# The Questions!\n",
    "\n",
    "Here is our chance to come up with some conclusions about our data set.  There are a few things about real estate that everyone always talks about, so now we can see if our data backs up all that talk\n",
    "\n",
    "## What is the single biggest impact on housing price?\n",
    "     Is it really about location?\n",
    "## How much does the size of the property matter?\n",
    "     Do we think it's more about the number of rooms, the lot size, or the square footage?\n",
    "## What is the impact of having a property on the waterfront?  \n",
    "     Is this a big factor in housing price?  Does it really increase price like I think it would? \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally we're ready to begin Modeling.\n",
    "\n",
    "We're going to start building our model.  We're going to put our categorical variables as the predictor in our model so we'll run a few (one for each categorical variable).\n",
    "\n",
    "As you will notice, our OSEMN process is iterative.  You can really see how we think through things that way in the modelling step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a loop to look at each column in turn as a single predictor for housing price\n",
    "col_names = df_pred.describe().columns.drop(['price','id'])\n",
    "results=[['ind_var', 'r_squared','intercept', 'slope','p_value']]\n",
    "for idx, val in enumerate(col_names):\n",
    "    print(\"price~\"+val)\n",
    "    print(\"--------------------------\")\n",
    "    f = 'price~'+val\n",
    "    model= smf.ols(formula =f, data=df_pred).fit()\n",
    "    X_new = pd.DataFrame({val: [df_pred[val].min(), df_pred[val].max()]});\n",
    "    preds= model.predict(X_new)\n",
    "    results.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1]])\n",
    "    print(results[idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shoot! our R-Squared Values are low.  Let's see if we can fix that by transforming our target (price!) into a log of itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we'll have a look at the log\n",
    "np.log(df_pred['price']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting that column of our dataframe to a log of itself and resaving that dataframe\n",
    "pred_log = df_pred\n",
    "pred_log['price'] = np.log(pred_log['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at a histogram to see if taking the log improved the distibution\n",
    "pred_log['price'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa! what a difference!  Ok, so now we can repeat our OLS from above but this time using the log of price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = pred_log.describe().columns.drop(['price','id'])\n",
    "results_log=[['ind_var', 'r_squared','intercept', 'slope','p_value']]\n",
    "for idx, val in enumerate(col_names):\n",
    "    print(\"Housing price~\"+val)\n",
    "    print(\"--------------------------\")\n",
    "    f = 'price~'+val\n",
    "    model= smf.ols(formula =f, data=pred_log).fit()\n",
    "    X_new = pd.DataFrame({val: [pred_log[val].min(), pred_log[val].max()]});\n",
    "    preds= model.predict(X_new)\n",
    "    results_log.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1]])\n",
    "    print(results_log[idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much better.  This model has 25 variables though, and I think we can cut that down significantly.  We'll get rid of the poor predictors where R-Squared is less than 0.01 and we'll drop at least one column from each categorical variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_log.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_final = pred_log\n",
    "house_final = house_final.drop([\"id\",'yr_built',\"zipcode\",\"long\",'sqft_lot15','bed_11','condition_5'],axis=1)\n",
    "house_final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data check to make sure something wasn't introduced when we were working on our dataset\n",
    "house_final.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooops! We managed to get almost of a whole row with new na's.  I bet we can fix it by removing that row.  We can do this by setting the data frame equal to a single series that is all not null.  \n",
    "\n",
    "Good thing we thought to check! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_final = house_final[house_final.date.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_final.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to make sure we still have enough data we'll have another look at the dataframe statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_final.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks Great!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting here to get to the best fit model that would answer our questions (which we will return to shortly), we can use feature ranking with recursive feature elimination on our dataset.  But before we do that we will spilt our data into two chunks; one for training our model and one for testing our model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have bunch of libraries and library features we will import here to do both our train-test split\n",
    "#and to do the RFE(recursive feature elimination) for us; and finally importing the regression modeler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a matrix so that we can begin our rfe\n",
    "#we have to take the date column out or our rfe function will throw errors\n",
    "y = house_final[[\"price\"]]\n",
    "X = house_final.drop(['price', 'date'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we're going to do an 20/80 split ; 20% of the data to test the model and the rest to train it\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 3)\n",
    "\n",
    "MSE_test=[]\n",
    "MSE_train=[]\n",
    "list_n= list(range(5,86,10))\n",
    "\n",
    "for n in list_n:\n",
    "    select_n = RFE(linreg, n_features_to_select = n)\n",
    "    select_n = select_n.fit(X_train,np.ravel(y_train))\n",
    "    selected_columns = X.columns[select_n.support_]\n",
    "    linreg.fit(X_train[selected_columns],y_train)\n",
    "    yhat_train = linreg.predict(X_train[selected_columns])\n",
    "    yhat_test = linreg.predict(X_test[selected_columns])\n",
    "    mse_train = np.sum((y_train - yhat_train)**2)/len(y_train)\n",
    "    mse_test = np.sum((y_test - yhat_test)**2)/len(y_test)\n",
    "    print(mse_train)\n",
    "    print(mse_test)\n",
    "    MSE_test.append(mse_test)\n",
    "    MSE_train.append(mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is too many variables to really get a good sense of how they affect our model.  Additionally, with all the categorical varibles on-hot encoded, some of the test data would have columns with almsot all 0s.  You can imagine how that could negatively affect the accuracy of our model.  Maybe we should move to a model with fewer predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we're moving out of scikit and back to stats models so we'll need to import the relevant parts before we try agian\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running our regression model\n",
    "X_int = sm.add_constant(X)\n",
    "model = sm.OLS(y,X_int.astype(float)).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bedrooms columns when they get to higher numbers of bedrooms are very rare values and they are throwing off our mosel.  We should get rid of these predictors and rerun our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house_final.drop(['price', 'date', 'bed_1', 'bed_2', 'bed_3', 'bed_4', \n",
    "                      'bed_5', 'bed_6', 'bed_7', 'bed_8', 'bed_9', 'bed_10'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_int = sm.add_constant(X)\n",
    "model = sm.OLS(y,X_int.astype(float)).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iNterpreting the model we created\n",
    "\n",
    "The coefficients for the  model we just created can be interpreted as follows:  how does the log of price change for each additional unit of X.  Where the X can be our predictors: the squarefeet of the living space, whether there is a waterfront on the property or how many floors the home has.  It's a little more complicated than using price un-trasformed but it worked much better for our model. As it stands now, our model explains about 70% of the variation in the log(price).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizing The Model\n",
    "\n",
    "I think we have a lot of variables here.  We can pick our top three and rerun the model to see if we can explain a good protion of the change in our home price while keeping things a little simpler.  Then we can make a formula for our model, that we can use on real world data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another iteration of a regression\n",
    "X = house_final.drop(['price', 'date', 'bed_1', 'bed_2', 'bed_3', 'bed_4', \n",
    "                      'bed_5', 'bed_6', 'bed_7', 'bed_8', 'bed_9', 'bed_10',\n",
    "                     'sqft_basement', 'yr_renovated', 'sqft_lot','sqft_living',\n",
    "                     'view', 'condition_1', 'condition_2', 'condition_3', 'condition_4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_int = sm.add_constant(X)\n",
    "model = sm.OLS(y,X_int.astype(float)).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we have it! we can look at the model below and plug in our values and get a predicted value for our housing prices!\n",
    "\n",
    "### log(price) = 0.279*floors + 1.093*waterfront + 1.660*latitude - 66.330 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to the Questions!\n",
    "\n",
    "## What is the single biggest impact on housing price?\n",
    "     Is it really about location?\n",
    "     \n",
    "   Why yes it is!  Turns out, Latitude had a big part to play in the variation amongst different housing prices.  I'm rather surprised that zipcode didn't have a bigger impact than latitude. \n",
    "     \n",
    "## How much does the size of the property matter?\n",
    "     Do we think it's more about the number of rooms, the lot size, or the square footage?\n",
    "     \n",
    "   Seems that size also matters a lot.  In our final model, the number of floors was a good predictor.  In our previous, more complicated model, we had a number of predictors realted to size, so we can assume that it plays a big role both in general and more specifically as the number of floors.  \n",
    "     \n",
    "     \n",
    "## What is the impact of having a property on the waterfront?  \n",
    "     Is this a big factor in housing price?  Does it really increase price like I think it would? \n",
    "     \n",
    "   Well, this answer is also yes!  When I asked myself this question I thought perhaps that I might find there were other factors that are more important.  I am actually surprised at how large the coefficient is, though.  I guess these properties are really *that much more* desireable.  (I can certainly say I would want one!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And there we have it!\n",
    "\n",
    "We followed the OSEMN process to clean, model, and interpret the Kings County Dataset.  We saw that each step was iterative, and that even as we progessed through the model, we went back to previous steps and moved on again.  \n",
    "\n",
    "What we learned about the date through exploration and through the model itself, we can bring back to the business users and help them some forecasts or predictions using our model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And if we had more time..\n",
    "\n",
    "There are a number of things I would add if I had more time to work on this data.\n",
    "\n",
    "1. Adding a map can help visualize some of the conclusions we made about location.\n",
    "2. Taking another look at the dates of the sales.  We could try to see if prices are really higher in the summer when more people are looking to buy\n",
    "3. Reviewing out scaling process and trying a different method to see if it gives us better results"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
